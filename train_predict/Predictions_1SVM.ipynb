{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sqlalchemy import create_engine\n",
    "import pyarrow.feather as feather\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())\n",
    "print(Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-bones",
   "metadata": {},
   "source": [
    "## Get predictions for the rest of ~20k proteins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open database connection\n",
    "engine = create_engine(\"mysql+pymysql://tcrd@tcrd.kmc.io:3306/tcrd6134pharos2\") # latest version\n",
    "dfprotein2020 = pd.read_sql_query(\"\"\"\n",
    "  select \n",
    "  protein.id,\n",
    "  protein.uniprot,\n",
    "  protein.name,\n",
    "  protein.sym,\n",
    "  target.tdl\n",
    "from\n",
    "  protein\n",
    "  join t2tc on protein.id=t2tc.protein_id\n",
    "  join target on t2tc.target_id=target.id\n",
    "order by\n",
    "  protein.id\n",
    " \"\"\", engine)\n",
    "engine = create_engine(\"mysql+pymysql://tcrd@tcrd.kmc.io:3306/tcrd540\") # 2018 version\n",
    "dfprotein2018 = pd.read_sql_query(\"\"\"\n",
    "  select \n",
    "  protein.id,\n",
    "  protein.uniprot,\n",
    "  protein.name,\n",
    "  protein.sym,\n",
    "  target.tdl\n",
    "from\n",
    "  protein\n",
    "  join t2tc on protein.id=t2tc.protein_id\n",
    "  join target on t2tc.target_id=target.id\n",
    "order by\n",
    "  protein.id\n",
    " \"\"\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-operation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tdllist = dfprotein2020[(dfprotein2020[\"uniprot\"].isin(dfprotein2018[\"uniprot\"]))]\n",
    "data = pd.read_feather(\"v5data.feather\") # read in data for predictions\n",
    "data.dropna(subset=['uniprot'], inplace=True)\n",
    "datadummy = data\n",
    "datadummy['tdl2'] = datadummy.apply(\n",
    "    lambda row: tdllist[tdllist['uniprot'] == row['uniprot']]['tdl'].values[0] \n",
    "    if row['uniprot'] in tdllist['uniprot'].values \n",
    "    else row['tdl'],\n",
    "    axis=1\n",
    ")\n",
    "datadummy.drop(columns = [\"tdl\"], inplace=True)\n",
    "datadummy.rename(columns = {\"tdl2\":\"tdl\"}, inplace=True)\n",
    "data = datadummy\n",
    "only_in_dfprotein2020 = dfprotein2020[~(dfprotein2020['uniprot'].isin(data['uniprot']))] # these proteins are in the latest pharos version but not in the 2018 version, so need to develop features for these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the developed features for proteins which are in the latest version of Pharos but not in the 2018 version\n",
    "file_path = 'v5data2020.feather'  \n",
    "output_file_path = 'only_in_dfprotein2020.feather'  # Path to store the selected rows in Feather format\n",
    "list_of_strings = only_in_dfprotein2020['uniprot'].unique()\n",
    "# Read only the selected rows based on the condition without loading the entire file\n",
    "df = feather.read_feather(file_path)\n",
    "# Filter the DataFrame based on the condition\n",
    "selected_df = df[df['uniprot'].isin(list_of_strings)]\n",
    "# Write the selected rows to the output Feather file\n",
    "feather.write_feather(selected_df, output_file_path)\n",
    "# Read the selected rows into a Pandas DataFrame if needed\n",
    "selected_rows = feather.read_feather(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = list(set(data.columns) - set(selected_rows.columns))\n",
    "for col in missing_cols:\n",
    "    selected_rows[col] = 0\n",
    "# Reorder 'selected_rows' columns to match 'data' columns order\n",
    "selected_rows = selected_rows[data.columns]\n",
    "# Concatenate both DataFrames row-wise\n",
    "combined_df = pd.concat([data, selected_rows], ignore_index=True)\n",
    "testntrain = pd.read_csv(\"testandtrainlist.csv\")\n",
    "data = combined_df\n",
    "contcols = (data.drop([\"uniprot\", \"protein_id\",  \"name\", \"sym\", \"tdl\" ], axis=1)).fillna(0)\n",
    "df1 = data[[\"uniprot\", \"protein_id\",  \"name\", \"sym\", \"tdl\"]]\n",
    "df1 = pd.concat([df1.reset_index(drop=True), contcols], axis=1)\n",
    "conditions = [\n",
    "    (df1['tdl'] == \"Tclin\"),\n",
    "    (df1['tdl'] != \"Tclin\")\n",
    "    ]\n",
    "values = [1, 0]\n",
    "df1['y'] = np.select(conditions, values)\n",
    "\n",
    "alltest = df1.loc[df1[\"uniprot\"].isin(dfprotein2020[\"uniprot\"])]\n",
    "alltest = alltest.loc[~(alltest[\"uniprot\"].isin(testntrain[\"uniprot\"]))]\n",
    "\n",
    "all_actual_test = alltest\n",
    "alltest = all_actual_test.loc[all_actual_test[\"tdl\"] != \"Tclin\"]\n",
    "\n",
    "tclintest = all_actual_test.loc[all_actual_test[\"tdl\"] == \"Tclin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(\"1svm_best_model.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-people",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_alltest = alltest.drop([\"uniprot\", \"protein_id\",  \"sym\", \"tdl\", \"y\", \"name\" ], axis=1)\n",
    "y_alltest = alltest[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "testpredictions = loaded_model.predict(X_alltest)\n",
    "scores = loaded_model.score_samples(X_alltest)\n",
    "ypred = testpredictions\n",
    "print(\"Predictions are : \", ypred)\n",
    "n_error_test = testpredictions[testpredictions == 1].size\n",
    "print(\"Test error = \", n_error_test/(len(X_alltest)))\n",
    "print(\"Wrong predictions = \", n_error_test, \"/19708\") # 5 proteins are in the set of 24 for 2020 pharos version \n",
    "print(\"Correct predictions = \", testpredictions[testpredictions == -1].size, \"/19708\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-timber",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_alltest = y_alltest.replace(0, -1)\n",
    "print(\"Accuracy = \", accuracy_score(y_alltest,ypred, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpred = alltest[[\"uniprot\", \"sym\", \"tdl\"]].reset_index(level=0)\n",
    "dfpred['predictions']=pd.Series(ypred)\n",
    "\n",
    "scores = pd.DataFrame(scores)\n",
    "scores.rename(columns = {0:'scores'\n",
    "                          }, inplace=True)\n",
    "\n",
    "probs_svc = loaded_model.decision_function(X_alltest)\n",
    "dfpred['decision_probs']=pd.Series(probs_svc)\n",
    "probs_svm = pd.Series(probs_svc - probs_svc.min()) / (probs_svc.max() - probs_svc.min())\n",
    "\n",
    "dfpred = pd.concat([dfpred, scores, probs_svm], axis=1).sort_values(\"uniprot\")\n",
    "\n",
    "dfpred.rename(columns = {'predictions':'predictions(1=tclin)', 0: \"Derivedprobability\"\n",
    "                          }, inplace=True)\n",
    "\n",
    "dfpred['predictions(1=tclin)'] = dfpred['predictions(1=tclin)'].replace([-1], 0)\n",
    "dfpred.to_csv(\"svm_allpreds.csv\", index=False)\n",
    "def assign_value(row):\n",
    "    if row['tdl'] == 'Tclin':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "dfpred['y'] = dfpred.apply(lambda row: assign_value(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tclintest = tclintest.drop([\"uniprot\", \"protein_id\",  \"sym\", \"tdl\", \"y\", \"name\" ], axis=1)\n",
    "y_tclintest = tclintest[\"y\"]\n",
    "testpredictions = loaded_model.predict(X_tclintest)\n",
    "scores = loaded_model.score_samples(X_tclintest)\n",
    "ypred = testpredictions\n",
    "print(\"Predictions are : \", ypred)\n",
    "n_error_test = testpredictions[testpredictions == -1].size\n",
    "print(\"Test error = \", n_error_test/(len(X_tclintest)))\n",
    "print(\"Wrong predictions = \", n_error_test, \"/24\") # 5 proteins from here are non-tclins\n",
    "print(\"Correct predictions = \", testpredictions[testpredictions == 1].size, \"/24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tclintest = y_tclintest.replace(0, -1)\n",
    "dfpred = tclintest[[\"uniprot\", \"sym\", \"tdl\"]].reset_index(level=0)\n",
    "dfpred['predictions']=pd.Series(ypred)\n",
    "\n",
    "scores = pd.DataFrame(scores)\n",
    "scores.rename(columns = {0:'scores'\n",
    "                          }, inplace=True)\n",
    "\n",
    "probs_svc = loaded_model.decision_function(X_tclintest)\n",
    "dfpred['decision_probs']=pd.Series(probs_svc)\n",
    "probs_svm = pd.Series(probs_svc - probs_svc.min()) / (probs_svc.max() - probs_svc.min())\n",
    "#probs_svm\n",
    "dfpred = pd.concat([dfpred, scores, probs_svm], axis=1).sort_values(\"uniprot\")\n",
    "\n",
    "dfpred.rename(columns = {'predictions':'predictions(1=tclin)', 0: \"Derivedprobability\"\n",
    "                          }, inplace=True)\n",
    "dfpred['predictions(1=tclin)'] = dfpred['predictions(1=tclin)'].replace([-1], 0)\n",
    "dfpred.to_csv(\"svm_24tclins.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-jhub_2]",
   "language": "python",
   "name": "conda-env-.conda-jhub_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
