{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())\n",
    "print(Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-perception",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_feather(\"v5data.feather\")\n",
    "data.dropna(subset=['uniprot'], inplace=True)\n",
    "contcols = (data.drop([\"uniprot\", \"protein_id\",  \"name\", \"sym\", \"tdl\" ], axis=1)).fillna(0)\n",
    "df1 = data[[\"uniprot\", \"protein_id\",  \"name\", \"sym\", \"tdl\"]]\n",
    "df1 = pd.concat([df1.reset_index(drop=True), contcols], axis=1)\n",
    "# changing the 5 proteins to tclins  \n",
    "renameids = [\"P02787\", \"O60840\", \"P13639\", \"Q16637\", \"Q9UM01\"] # these 5 proteins are marked nontclins in latest Pharos\n",
    "df1.loc[df1[\"uniprot\"].isin(renameids), 'tdl'] = 'Tclin'\n",
    "conditions = [\n",
    "    (df1['tdl'] == \"Tclin\"),\n",
    "    (df1['tdl'] != \"Tclin\")\n",
    "    ]\n",
    "values = [1, 0]\n",
    "df1['y'] = np.select(conditions, values)\n",
    "dummy = pd.read_csv(\"nontclin1290.csv\") # these proteins are in a random order\n",
    "nontclin = dummy.head(611)\n",
    "nontclin = nontclin.drop_duplicates()\n",
    "nontclin_bottom = dummy.tail(dummy.shape[0] - 611) # Using 611 non-tclins from the 1SVM models\n",
    "\n",
    "tdark = nontclin[[\"sym\", \"uniprot\"]]\n",
    "tdark = tdark.drop_duplicates()   \n",
    "tdarkuniprotid = tdark[\"uniprot\"]\n",
    "tdark[\"NewTClin\"] = \"blank\"\n",
    "tdark[\"Quinquennal\"] = \"blank\"\n",
    "tclin = pd.read_csv(\"Tclin_list.csv\")\n",
    "tclin = tclin[['UniProt', 'Symbol', 'NewTClin','Quinquennal']]\n",
    "tclin.rename(columns = {'UniProt':'uniprot', 'Symbol': 'sym'}, inplace=True)\n",
    "tclinuniprotid = tclin[\"uniprot\"]\n",
    "tlist = pd.concat([tdark, tclin]) \n",
    "tlist.drop([\"sym\",  \"Quinquennal\"], axis=1, inplace=True)\n",
    "ids = tlist[\"uniprot\"]\n",
    "df = df1.loc[df1['uniprot'].isin(ids)]\n",
    "df = pd.merge(df, tlist, on ='uniprot')\n",
    "df = df.sort_values(\"uniprot\", ascending=False)\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "df1 = df.loc[~df['uniprot'].isin(renameids)]\n",
    "df2 = df.loc[df['uniprot'].isin(renameids)]\n",
    "df2[\"NewTClin\"] = \"Y\"\n",
    "df = pd.concat([df1, df2]) \n",
    "test = df.loc[df['NewTClin'] == \"Y\"] \n",
    "train = df.loc[df['NewTClin'] != \"Y\"] \n",
    "\n",
    "test[\"tdl\"] = 'Tclin'\n",
    "conditions = [\n",
    "    (test['tdl'] == \"Tclin\"),\n",
    "    (test['tdl'] != \"Tclin\")\n",
    "    ]\n",
    "values = [1, 0]\n",
    "test['y'] = np.select(conditions, values)\n",
    "train = train.loc[train[\"tdl\"] != \"Tchem\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64421d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop([\"uniprot\", \"protein_id\",  \"name\",\"sym\", \"tdl\", \"y\", \"NewTClin\" ], axis=1)\n",
    "y_train = train[\"y\"]\n",
    "X_test = test.drop([\"uniprot\", \"protein_id\", \"name\" ,\"sym\", \"tdl\", \"y\", \"NewTClin\" ], axis=1)\n",
    "y_test = test[\"y\"]\n",
    "print(\"Total Features columns = \", len(X_train.columns.values.tolist()))\n",
    "print(\"Training rows = \", len(X_train))\n",
    "print(\"Testing rows = \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-reviewer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "I=1000\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "params = { 'max_depth': np.arange(3,20,1),\n",
    "           'learning_rate': np.arange(0.01, 0.5, 0.01),\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'gamma': np.arange(0,10,0.05), \n",
    "           'reg_alpha': np.arange(0,80,1), \n",
    "           'reg_lambda': np.arange(0,1,0.1), \n",
    "           'n_estimators': [100, 500, 1000]} \n",
    "scoring = {'Accuracy': 'accuracy', 'f1': 'f1'\n",
    "           }\n",
    "start = time.time()\n",
    "xgbc = xgb.XGBClassifier(seed = 40)\n",
    "kfold = KFold(n_splits=2, shuffle=True, random_state=40)\n",
    "clf = RandomizedSearchCV(estimator=xgbc,\n",
    "                         param_distributions=params,\n",
    "                         scoring=scoring,\n",
    "                         n_iter=I,\n",
    "                         verbose=2,\n",
    "                          n_jobs=1,refit='Accuracy',return_train_score=False, random_state = 40, cv=kfold)\n",
    "## change n_jobs to use more cores\n",
    "clf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "allresults = clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = (clf.predict_proba(X_test)) \n",
    "ypred = (clf.predict(X_test))\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Predictions = \", ypred)\n",
    "print(\"Correct predictions = \", ypred.sum(), \"/74\")\n",
    "print(\"Accuracy = \", accuracy_score(y_test,ypred, normalize=True))\n",
    "print(\"F1 score = \", f1_score(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-pledge",
   "metadata": {},
   "source": [
    "## Get predictions and the probabilities for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpred = test[[\"uniprot\", \"sym\", \"tdl\", \"NewTClin\"]]\n",
    "dfpred = dfpred.reset_index(level=0)\n",
    "dfpred['predictions']=pd.Series(ypred)\n",
    "probdf = pd.DataFrame(probs)\n",
    "dfpred = pd.concat([dfpred, probdf], axis=1).sort_values(\"uniprot\")\n",
    "dfpred.rename(columns = {'predictions':'predictions(1=tclin)', 0: \"probablity_nontclin\",\n",
    "                          1: \"probability_tclin\"}, inplace=True)\n",
    "dfpred.to_csv(\"xgb_74preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best XGB model\n",
    "best_model = clf.best_estimator_\n",
    "# Save model\n",
    "pickle.dump(clf.best_estimator_, open(\"xgb_best_model.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-cheat",
   "metadata": {},
   "source": [
    "## GET THE FEATURE IMP PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-variable",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imp = pd.DataFrame()\n",
    "imp['features']=pd.Series(X_train.columns.values)\n",
    "imp['importancescore']=pd.Series((prd.best_estimator_.feature_importances_))\n",
    "imp = imp.sort_values(\"importancescore\", ascending = False)\n",
    "df44 = pd.DataFrame()\n",
    "df44[\"importancefscore\"] = pd.Series(prd.best_estimator_.get_booster().get_fscore())\n",
    "df44 = df44.reset_index(level=0)\n",
    "df44.rename(columns = {'index':'features'}, inplace=True)\n",
    "imp = pd.merge(imp, df44, on ='features', how=\"left\")\n",
    "gain = pd.DataFrame()\n",
    "gain[\"gain\"] = pd.Series(prd.best_estimator_.get_booster().get_score(importance_type=\"gain\"))\n",
    "gain = gain.reset_index(level=0)\n",
    "gain.rename(columns = {'index':'features'}, inplace=True)\n",
    "imp = pd.merge(imp, gain, on ='features', how=\"left\")\n",
    "cover = pd.DataFrame()\n",
    "cover[\"cover\"] = pd.Series(prd.best_estimator_.get_booster().get_score(importance_type=\"cover\"))\n",
    "cover = cover.reset_index(level=0)\n",
    "cover.rename(columns = {'index':'features'}, inplace=True)\n",
    "imp = pd.merge(imp, cover, on ='features', how=\"left\")\n",
    "imp[[\"importancescore\",\"importancefscore\", \"gain\", \"cover\"]] = imp[[\"importancescore\",\"importancefscore\", \"gain\", \"cover\"]].fillna(0)\n",
    "imp.to_csv(\"feat_imp.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-jhub_2]",
   "language": "python",
   "name": "conda-env-.conda-jhub_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
