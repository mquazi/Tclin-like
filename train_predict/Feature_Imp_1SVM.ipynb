{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import shap\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())\n",
    "print(Path.cwd())\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(\"1svm_best_model.pickle\", 'rb'))\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_feather(\"v5data.feather\")\n",
    "data.dropna(subset=['uniprot'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "contcols = (data.drop([\"uniprot\", \"protein_id\",  \"name\", \"sym\", \"tdl\" ], axis=1)).fillna(0)\n",
    "df1 = data[[\"uniprot\", \"protein_id\",  \"name\", \"sym\", \"tdl\"]]\n",
    "df1 = pd.concat([df1.reset_index(drop=True), contcols], axis=1)\n",
    "# changing the 5 proteins to tclins  \n",
    "renameids = [\"P02787\", \"O60840\", \"P13639\", \"Q16637\", \"Q9UM01\"]\n",
    "df1.loc[df1[\"uniprot\"].isin(renameids), 'tdl'] = 'Tclin'\n",
    "\n",
    "conditions = [\n",
    "    (df1['tdl'] == \"Tclin\"),\n",
    "    (df1['tdl'] != \"Tclin\")\n",
    "    ]\n",
    "values = [1, 0]\n",
    "df1['y'] = np.select(conditions, values)\n",
    "tclin = pd.read_csv(\"Tclin_list.csv\")\n",
    "tclin = tclin[['UniProt', 'Symbol', 'NewTClin','Quinquennal']]\n",
    "tclin.rename(columns = {'UniProt':'uniprot', 'Symbol': 'sym'}, inplace=True)\n",
    "tclinuniprotid = tclin[\"uniprot\"]\n",
    "tlist = tclin # First 709 are tclins \n",
    "tlist.drop([\"sym\",  \"Quinquennal\"], axis=1, inplace=True)\n",
    "\n",
    "ids = tlist[\"uniprot\"]\n",
    "df = df1.loc[df1['uniprot'].isin(ids)]\n",
    "df = pd.merge(df, tlist, on ='uniprot')\n",
    "df = df.sort_values(\"uniprot\", ascending=False)\n",
    "\n",
    "df1 = df.loc[~df['uniprot'].isin(renameids)]\n",
    "df2 = df.loc[df['uniprot'].isin(renameids)]\n",
    "df2[\"NewTClin\"] = \"Y\"\n",
    "\n",
    "df = pd.concat([df1, df2]) \n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "test = df.loc[df['NewTClin'] == \"Y\"] \n",
    "train = df.loc[df['NewTClin'] != \"Y\"] \n",
    "test[\"tdl\"] = 'Tclin'\n",
    "conditions = [\n",
    "    (test['tdl'] == \"Tclin\"),\n",
    "    (test['tdl'] != \"Tclin\")\n",
    "    ]\n",
    "values = [1, 0]\n",
    "test['y'] = np.select(conditions, values)\n",
    "train = train.loc[train[\"y\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop([\"uniprot\", \"protein_id\",  \"name\",\"sym\", \"tdl\", \"y\", \"NewTClin\" ], axis=1)\n",
    "y_train = train[\"y\"]\n",
    "X_test = test.drop([\"uniprot\", \"protein_id\", \"name\" ,\"sym\", \"tdl\", \"y\", \"NewTClin\" ], axis=1)\n",
    "y_test = test[\"y\"]\n",
    "print(\"Total Features columns = \", len(X_train.columns.values.tolist()))\n",
    "print(\"Training rows = \", len(X_train))\n",
    "print(\"Testing rows = \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model is the trained 1SVM model\n",
    "explainer = shap.Explainer(loaded_model, X_train)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Summary plot of SHAP values\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_abs_shap_values = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# Get the indices of the top 50 features\n",
    "top_50_indices = np.argsort(mean_abs_shap_values)[-50:][::-1]\n",
    "\n",
    "# Extract the top 50 feature names based on your X_train dataset\n",
    "top_50_features = X_train.columns[top_50_indices]\n",
    "\n",
    "# Display top 50 feature names\n",
    "print(\"Top 50 Features:\")\n",
    "print(top_50_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_features_df = pd.DataFrame(top_50_features, columns=['9_1TopFeatures'])\n",
    "\n",
    "# Save top 50 features to a CSV file\n",
    "top_50_features_df.to_csv('top_50_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-jhub_2]",
   "language": "python",
   "name": "conda-env-.conda-jhub_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
