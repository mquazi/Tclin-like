{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "import pyarrow.feather as feather\n",
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())\n",
    "print(Path.cwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-bones",
   "metadata": {},
   "source": [
    "## Get predictions for the rest of ~20k proteins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open database connection\n",
    "engine = create_engine(\"mysql+pymysql://tcrd@tcrd.kmc.io:3306/tcrd6134pharos2\") # latest version\n",
    "dfprotein2020 = pd.read_sql_query(\"\"\"\n",
    "  select \n",
    "  protein.id,\n",
    "  protein.uniprot,\n",
    "  protein.name,\n",
    "  protein.sym,\n",
    "  target.tdl\n",
    "from\n",
    "  protein\n",
    "  join t2tc on protein.id=t2tc.protein_id\n",
    "  join target on t2tc.target_id=target.id\n",
    "order by\n",
    "  protein.id\n",
    " \"\"\", engine)\n",
    "engine = create_engine(\"mysql+pymysql://tcrd@tcrd.kmc.io:3306/tcrd540\") # 2018 version\n",
    "dfprotein2018 = pd.read_sql_query(\"\"\"\n",
    "  select \n",
    "  protein.id,\n",
    "  protein.uniprot,\n",
    "  protein.name,\n",
    "  protein.sym,\n",
    "  target.tdl\n",
    "from\n",
    "  protein\n",
    "  join t2tc on protein.id=t2tc.protein_id\n",
    "  join target on t2tc.target_id=target.id\n",
    "order by\n",
    "  protein.id\n",
    " \"\"\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdllist = dfprotein2020[(dfprotein2020[\"uniprot\"].isin(dfprotein2018[\"uniprot\"]))]\n",
    "data = pd.read_feather(\"v5data.feather\")\n",
    "data.dropna(subset=['uniprot'], inplace=True)\n",
    "datadummy = data\n",
    "datadummy['tdl2'] = datadummy.apply(\n",
    "    lambda row: tdllist[tdllist['uniprot'] == row['uniprot']]['tdl'].values[0] \n",
    "    if row['uniprot'] in tdllist['uniprot'].values \n",
    "    else row['tdl'],\n",
    "    axis=1\n",
    ")\n",
    "datadummy.drop(columns = [\"tdl\"], inplace=True)\n",
    "datadummy.rename(columns = {\"tdl2\":\"tdl\"}, inplace=True)\n",
    "data = datadummy\n",
    "only_in_dfprotein2020 = dfprotein2020[~(dfprotein2020['uniprot'].isin(data['uniprot']))] # these proteins are in the latest pharos version but not in the 2018 version, so need to develop features for these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the developed features for proteins which are in the latest version of Pharos but not in the 2018 version\n",
    "file_path = 'v5data2020.feather'  \n",
    "output_file_path = 'only_in_dfprotein2020.feather'  \n",
    "list_of_strings = only_in_dfprotein2020['uniprot'].unique()\n",
    "# Read only the selected rows based on the condition without loading the entire file\n",
    "df = feather.read_feather(file_path)\n",
    "# Filter the DataFrame based on the condition\n",
    "selected_df = df[df['uniprot'].isin(list_of_strings)]\n",
    "# Write the selected rows to the output Feather file\n",
    "feather.write_feather(selected_df, output_file_path)\n",
    "# Read the selected rows into a Pandas DataFrame if needed\n",
    "selected_rows = feather.read_feather(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = list(set(data.columns) - set(selected_rows.columns))\n",
    "for col in missing_cols:\n",
    "    selected_rows[col] = 0\n",
    "# Reorder 'selected_rows' columns to match 'data' columns order\n",
    "selected_rows = selected_rows[data.columns]\n",
    "\n",
    "# Concatenate both DataFrames row-wise\n",
    "combined_df = pd.concat([data, selected_rows], ignore_index=True)\n",
    "testntrain = pd.read_csv(\"testandtrainlist.csv\")\n",
    "data = combined_df\n",
    "contcols = (data.drop([\"uniprot\", \"protein_id\",  \"name\", \"sym\", \"tdl\" ], axis=1)).fillna(0)\n",
    "df1 = data[[\"uniprot\", \"protein_id\",  \"name\", \"sym\", \"tdl\"]]\n",
    "df1 = pd.concat([df1.reset_index(drop=True), contcols], axis=1)\n",
    "\n",
    "# changing the 5 proteins to tclins  \n",
    "renameids = [\"P02787\", \"O60840\", \"P13639\", \"Q16637\", \"Q9UM01\"] # these proteins are in the latest pharos version but not in the 2018 version, so need to develop features for these\n",
    "df1.loc[df1[\"uniprot\"].isin(renameids), 'tdl'] = 'Tclin'\n",
    "\n",
    "conditions = [\n",
    "    (df1['tdl'] == \"Tclin\"),\n",
    "    (df1['tdl'] != \"Tclin\")\n",
    "    ]\n",
    "values = [1, 0]\n",
    "df1['y'] = np.select(conditions, values)\n",
    "test19 = df1.loc[df1[\"uniprot\"].isin(dfprotein2020[\"uniprot\"])]\n",
    "test19 = test19.loc[~(test19[\"uniprot\"].isin(testntrain[\"uniprot\"]))]\n",
    "test19 = test19.loc[test19[\"tdl\"] == \"Tclin\"]\n",
    "\n",
    "alltest = df1.loc[df1[\"uniprot\"].isin(dfprotein2020[\"uniprot\"])]\n",
    "alltest = alltest.loc[~(alltest[\"uniprot\"].isin(testntrain[\"uniprot\"]))]\n",
    "alltest = alltest.loc[alltest[\"tdl\"] != \"Tclin\"]\n",
    "alltest = alltest.head(18418)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-helmet",
   "metadata": {},
   "source": [
    "## All Non-tclin proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(\"xgb_best_model.pickle\", 'rb'))\n",
    "X_alltest = alltest.drop([\"uniprot\", \"protein_id\", \"name\" ,\"sym\", \"tdl\", \"y\" ], axis=1)\n",
    "y_alltest = alltest[\"y\"]\n",
    "allypred = (loaded_model.predict(X_alltest))\n",
    "allprobs = (loaded_model.predict_proba(X_alltest))\n",
    "dfpredall = alltest[[\"uniprot\", \"sym\", \"tdl\", \"y\"]]\n",
    "dfpredall = dfpredall.reset_index(level=0)\n",
    "dfpredall['predictions']=pd.Series(allypred)\n",
    "allprobdf = pd.DataFrame(allprobs)\n",
    "dfpredall = pd.concat([dfpredall, allprobdf], axis=1).sort_values(\"uniprot\")\n",
    "dfpredall.rename(columns = {'predictions':'predictions(1=tclin)', 0: \"probability_nontclin\",\n",
    "                          1: \"probability_tclin\"}, inplace=True)\n",
    "dfpredall.to_csv(\"xgb_allpreds.csv\", index=False)\n",
    "print(\"Correct predictions for 18418 non-tclins = \", \n",
    "      len(dfpredall.loc[(dfpredall[\"y\"] == 0) & \n",
    "                    (dfpredall[\"predictions(1=tclin)\"] == 0)]), \"/\", \n",
    "      len(dfpredall.loc[dfpredall[\"y\"] == 0]))\n",
    "print(\"Accuracy = \", accuracy_score(y_alltest,allypred, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-integral",
   "metadata": {},
   "source": [
    "## All tclin proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test19.drop([\"uniprot\", \"protein_id\", \"name\" ,\"sym\", \"tdl\", \"y\" ], axis=1)\n",
    "y_test = test19[\"y\"]\n",
    "ypred = (loaded_model.predict(X_test))\n",
    "probs = (loaded_model.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpred = test19[[\"uniprot\", \"sym\", \"tdl\", \"y\"]]\n",
    "dfpred = dfpred.reset_index(level=0)\n",
    "dfpred['predictions']=pd.Series(ypred)\n",
    "probdf = pd.DataFrame(probs)\n",
    "dfpred = pd.concat([dfpred, probdf], axis=1).sort_values(\"uniprot\")\n",
    "dfpred.rename(columns = {'predictions':'predictions(1=tclin)', 0: \"probability_nontclin\",\n",
    "                          1: \"probability_tclin\"}, inplace=True)\n",
    "dfpred.to_csv(\"xgb_19preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correct predictions for 19 tclins = \", \n",
    "      len(dfpred.loc[(dfpred[\"y\"] == 1) & \n",
    "                    (dfpred[\"predictions(1=tclin)\"] == 1)])-1, \"/\", \n",
    "      len(dfpred.loc[dfpred[\"y\"] == 1])-1)\n",
    "print(\"Accuracy = \", accuracy_score(y_test,ypred, normalize=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-jhub_2]",
   "language": "python",
   "name": "conda-env-.conda-jhub_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
