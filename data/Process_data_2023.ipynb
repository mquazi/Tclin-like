{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuNnDGwdifr6"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "# Open database connection\n",
    "engine = create_engine(\"mysql+pymysql://tcrd@tcrd.kmc.io:3306/tcrd6134pharos2\") # latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXRQVcbek4FM"
   },
   "outputs": [],
   "source": [
    "## fetch all the required TCRD tables... 7 of them \n",
    "dfprotein = pd.read_sql_query(\"\"\"\n",
    "  select \n",
    "  protein.id,\n",
    "  protein.uniprot,\n",
    "  protein.name,\n",
    "  protein.sym,\n",
    "  target.tdl\n",
    "from\n",
    "  protein\n",
    "  join t2tc on protein.id=t2tc.protein_id\n",
    "  join target on t2tc.target_id=target.id\n",
    "order by\n",
    "  protein.id\n",
    " \"\"\", engine)\n",
    "\n",
    "dfgo = pd.read_sql_query(\"\"\"\n",
    "select\n",
    "  goa.protein_id,\n",
    "  goa.go_id,\n",
    "  target.tdl\n",
    "from\n",
    "  goa\n",
    "  join t2tc on goa.protein_id=t2tc.protein_id\n",
    "  join target on t2tc.target_id=target.id\n",
    "order by\n",
    "  protein_id\n",
    "\"\"\", engine)\n",
    "\n",
    "dfpathway = pd.read_sql_query(\"\"\"\n",
    "select\n",
    "  pathway.protein_id,\n",
    "  pathway.id_in_source,\n",
    "  pathway.pwtype\n",
    "from\n",
    "pathway\n",
    "  join t2tc on pathway.protein_id=t2tc.protein_id\n",
    "  join target on t2tc.target_id=target.id\n",
    "order by\n",
    "  protein_id\n",
    "\"\"\", engine)\n",
    "dfpathway = dfpathway.loc[(dfpathway[\"pwtype\"] == \"Reactome\") | (dfpathway[\"pwtype\"] == \"KEGG\")]\n",
    "\n",
    "dfppi = pd.read_sql_query(\"\"\"\n",
    "select\n",
    "  ncats_ppi.protein_id,\n",
    "  ncats_ppi.ppitypes,\n",
    "  ncats_ppi.score,\n",
    "  ncats_ppi.other_id\n",
    "from\n",
    "ncats_ppi\n",
    "  join t2tc on ncats_ppi.protein_id=t2tc.protein_id\n",
    "WHERE ppitypes = 'STRINGDB'\n",
    "order by\n",
    "  protein_id\n",
    "\n",
    "\"\"\", engine)\n",
    "dfppi.rename(columns={'protein_id': 'protein_id1', 'other_id':'protein_id2'}, inplace=True)\n",
    "res = (dfppi[~dfppi.filter(like='protein_id').apply(frozenset, axis=1).duplicated()]\n",
    "       .reset_index(drop=True))\n",
    "res2 = res.pivot_table(\n",
    "    values='score', index='protein_id1', columns='protein_id2')\n",
    "res2.columns.name = None\n",
    "dfppi = res2.reset_index()\n",
    "dfppi = dfppi.add_prefix('PPI:')\n",
    "dfppi.rename(columns = {'PPI:protein_id1':'protein_id'}, inplace=True)\n",
    "\n",
    "dfhpa = pd.read_sql_query(\"\"\"\n",
    "select\n",
    "  expression.protein_id,\n",
    "  expression.tissue,\n",
    "  expression.etype,\n",
    "  expression.oid\n",
    "from\n",
    "expression\n",
    "  join t2tc on expression.protein_id=t2tc.protein_id\n",
    "WHERE etype = 'HPA Protein'\n",
    "order by\n",
    "  protein_id\n",
    "\"\"\", engine)\n",
    "dfhpa['tissue'] = 'HPA:' + dfhpa['tissue'].astype(str)\n",
    "\n",
    "dfgtex = pd.read_sql_query(\"\"\"\n",
    "select\n",
    "  gtex.protein_id,\n",
    "  gtex.tissue,\n",
    "  gtex.tpm,\n",
    "  gtex.uberon_id\n",
    "from\n",
    "gtex\n",
    "  join t2tc on gtex.protein_id=t2tc.protein_id\n",
    "order by\n",
    "  protein_id\n",
    "\"\"\", engine)\n",
    "dfgtex['tissue'] = 'GTEX:' + dfgtex['tissue'].astype(str)\n",
    "\n",
    "dfdis = pd.read_sql_query(\"\"\"\n",
    "select\n",
    " disease.protein_id,\n",
    " disease.name,\n",
    " disease.mondoid\n",
    "from\n",
    "  disease\n",
    "  join t2tc on disease.protein_id=t2tc.protein_id\n",
    "order by\n",
    "  protein_id\n",
    "\"\"\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for GTEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine all the dfs \n",
    "dfprotein.rename(columns={'id': 'protein_id'}, inplace=True)\n",
    "\n",
    "df = dfhpa[dfhpa['tissue'].notna()]\n",
    "hpadf = pd.crosstab(df[\"protein_id\"], df[\"tissue\"]).reset_index().rename_axis(columns=None)\n",
    "\n",
    "df = dfgo[dfgo['go_id'].notna()]\n",
    "godf = pd.crosstab(df[\"protein_id\"], df[\"go_id\"]).reset_index().rename_axis(columns=None)\n",
    "\n",
    "df = dfpathway[dfpathway['id_in_source'].notna()]\n",
    "pathwaydf = pd.crosstab(df[\"protein_id\"], df[\"id_in_source\"]).reset_index().rename_axis(columns=None)\n",
    "\n",
    "df = dfppi\n",
    "ppidf = df \n",
    "\n",
    "df = dfgtex[dfgtex['tissue'].notna()]\n",
    "gtexdf = pd.crosstab(df[\"protein_id\"], df[\"tissue\"]).reset_index().rename_axis(columns=None)\n",
    "\n",
    "df1 = dfprotein.set_index('protein_id')\n",
    "df2 = godf.set_index('protein_id')\n",
    "df3 = pathwaydf.set_index('protein_id')\n",
    "df4 = hpadf.set_index('protein_id')\n",
    "df5 = ppidf.set_index('protein_id')\n",
    "\n",
    "df6 = gtexdf.set_index('protein_id')\n",
    "gtex = df6\n",
    "df = pd.concat([df1,df2,df3,df4, df5, df6],axis=1,sort=False).reset_index()\n",
    "df.rename(columns = {'index':'protein_id'})\n",
    "df.to_feather(\"v3data2020.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for LINCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dflincs = pd.read_table('lincs.tsv') # lincs data from pharos at: https://drive.google.com/drive/folders/1P3-cBICdSzdXf7fiVS9qtKjdMZLANnwG?usp=sharing\n",
    "dflincs = dflincs.drop('Unnamed: 0', axis=1)\n",
    "dflincs = dflincs.add_prefix('LINCS:')\n",
    "dflincs.rename(columns = {'LINCS:protein_id':'protein_id'}, inplace=True)\n",
    "df = dflincs\n",
    "lincsdf = df\n",
    "\n",
    "df6 = lincsdf.set_index('protein_id')\n",
    "lincs = df6\n",
    "df = pd.concat([df1,df2,df3,df4, df5, df6],axis=1,sort=False).reset_index()\n",
    "df.rename(columns = {'index':'protein_id'})\n",
    "df.to_feather(\"v4data2020.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for DISEASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = dfdis[dfdis['mondoid'].notna()]\n",
    "disdf = pd.crosstab(df[\"protein_id\"], df[\"mondoid\"]).reset_index().rename_axis(columns=None)\n",
    "\n",
    "df6 = disdf.set_index('protein_id')\n",
    "dis = df6\n",
    "df = pd.concat([df1,df2,df3,df4, df5, df6],axis=1,sort=False).reset_index()\n",
    "df.rename(columns = {'index':'protein_id'})\n",
    "df.to_feather(\"v5data2020.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for CCLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfccle = pd.read_table('ccle.tsv') # ccle data from pharos at: https://drive.google.com/drive/folders/1P3-cBICdSzdXf7fiVS9qtKjdMZLANnwG?usp=sharing\n",
    "dfccle = dfccle.drop('Unnamed: 0', axis=1)\n",
    "dfccle.columns = dfccle.columns.str.split('(').str[-1]\n",
    "dfccle.columns = dfccle.columns.str.replace(')', '')\n",
    "\n",
    "df = dfccle\n",
    "ccledf = df\n",
    "\n",
    "df6 = ccledf.set_index('protein_id')\n",
    "ccle = df6\n",
    "df = pd.concat([df1,df2,df3,df4, df5, df6],axis=1,sort=False).reset_index()\n",
    "df.rename(columns = {'index':'protein_id'})\n",
    "df.to_feather(\"v6data2020.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for _ALL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2,df3,df4, df5, gtex, lincs, dis, ccle],axis=1,sort=False).reset_index()\n",
    "df.rename(columns = {'index':'protein_id'})\n",
    "df.dropna(subset=['uniprot'], inplace=True)\n",
    "df.to_feather('v13data2020.feather')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPvCDhdwnMye3251VfBoMQ3",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-jhub_2]",
   "language": "python",
   "name": "conda-env-.conda-jhub_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
