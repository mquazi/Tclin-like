{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuNnDGwdifr6"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "# Open database connection\n",
    "engine = create_engine(\"mysql+pymysql://tcrd@tcrd.kmc.io:3306/tcrd540\") # 2018 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXRQVcbek4FM"
   },
   "outputs": [],
   "source": [
    "## fetch all the required TCRD tables... 7 of them \n",
    "dfprotein = pd.read_sql_query(\"\"\"\n",
    "  select \n",
    "  protein.id,\n",
    "  protein.uniprot,\n",
    "  protein.name,\n",
    "  protein.sym,\n",
    "  target.tdl\n",
    "from\n",
    "  protein\n",
    "  join t2tc on protein.id=t2tc.protein_id\n",
    "  join target on t2tc.target_id=target.id\n",
    "order by\n",
    "  protein.id\n",
    " \"\"\", engine)\n",
    "\n",
    "dfgo = pd.read_sql_query(\"\"\"\n",
    "select\n",
    "  goa.protein_id,\n",
    "  goa.go_id,\n",
    "  target.tdl\n",
    "from\n",
    "  goa\n",
    "  join t2tc on goa.protein_id=t2tc.protein_id\n",
    "  join target on t2tc.target_id=target.id\n",
    "order by\n",
    "  protein_id\n",
    "\"\"\", engine)\n",
    "\n",
    "dfpathway = pd.read_sql_query(\"\"\"\n",
    "select\n",
    "  pathway.protein_id,\n",
    "  pathway.id_in_source,\n",
    "  pathway.pwtype\n",
    "from\n",
    "pathway\n",
    "  join t2tc on pathway.protein_id=t2tc.protein_id\n",
    "  join target on t2tc.target_id=target.id\n",
    "order by\n",
    "  protein_id\n",
    "\"\"\", engine)\n",
    "dfpathway = dfpathway.loc[(dfpathway[\"pwtype\"] == \"Reactome\") | (dfpathway[\"pwtype\"] == \"KEGG\")]\n",
    "\n",
    "dfhpa = pd.read_sql_query(\"\"\"\n",
    "select\n",
    "  expression.protein_id,\n",
    "  expression.tissue,\n",
    "  expression.etype,\n",
    "  expression.oid\n",
    "from\n",
    "expression\n",
    "  join t2tc on expression.protein_id=t2tc.protein_id\n",
    "WHERE etype = 'HPA Protein'\n",
    "order by\n",
    "  protein_id\n",
    "\"\"\", engine)\n",
    "dfhpa['tissue'] = 'HPA:' + dfhpa['tissue'].astype(str)\n",
    "\n",
    "dfgtex = pd.read_sql_query(\"\"\"\n",
    "select\n",
    "  expression.protein_id,\n",
    "  expression.tissue,\n",
    "  expression.etype,\n",
    "  expression.oid\n",
    "from\n",
    "expression\n",
    "  join t2tc on expression.protein_id=t2tc.protein_id\n",
    "WHERE etype = 'GTEx'\n",
    "order by\n",
    "  protein_id\n",
    "\"\"\", engine)\n",
    "dfgtex['tissue'] = 'GTEX:' + dfgtex['tissue'].astype(str)\n",
    "\n",
    "dfdis = pd.read_sql_query(\"\"\"\n",
    "select\n",
    " disease.protein_id,\n",
    " disease.name,\n",
    " disease.did\n",
    "from\n",
    "  disease\n",
    "  join t2tc on disease.protein_id=t2tc.protein_id\n",
    "order by\n",
    "  protein_id\n",
    "\"\"\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPIs are not available in the 2018 version, so get the PPIs from the 2020 version and subset the 2018 proteins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://tcrd@tcrd.kmc.io:3306/tcrd6134pharos2\") # latest version\n",
    "dfppi = pd.read_sql_query(\"\"\"\n",
    "select\n",
    "  ncats_ppi.protein_id,\n",
    "  ncats_ppi.ppitypes,\n",
    "  ncats_ppi.score,\n",
    "  ncats_ppi.other_id\n",
    "from\n",
    "ncats_ppi\n",
    "  join t2tc on ncats_ppi.protein_id=t2tc.protein_id\n",
    "WHERE ppitypes = 'STRINGDB'\n",
    "order by\n",
    "  protein_id\n",
    "\n",
    "\"\"\", engine)\n",
    "dfprotein2020 = pd.read_sql_query(\"\"\"\n",
    "  select \n",
    "  protein.id,\n",
    "  protein.uniprot,\n",
    "  protein.name,\n",
    "  protein.sym,\n",
    "  target.tdl\n",
    "from\n",
    "  protein\n",
    "  join t2tc on protein.id=t2tc.protein_id\n",
    "  join target on t2tc.target_id=target.id\n",
    "order by\n",
    "  protein.id\n",
    " \"\"\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = dfppi.merge(dfprotein2020[['id', 'uniprot']], left_on='protein_id', right_on='id', how='left')\n",
    "\n",
    "# Renaming the column to replace 'protein_id' values\n",
    "merged_df.rename(columns={'uniprot': 'proteinid'}, inplace=True)\n",
    "# Dropping the extra 'id' column\n",
    "merged_df.drop('id', axis=1, inplace=True)\n",
    "\n",
    "# Merging again for 'other_id'\n",
    "merged_df = merged_df.merge(dfprotein2020[['id', 'uniprot']], left_on='other_id', right_on='id', how='left')\n",
    "# Renaming and dropping as before\n",
    "merged_df.rename(columns={'uniprot': 'otherid'}, inplace=True)\n",
    "merged_df.drop(['id', 'protein_id', 'other_id'], axis=1, inplace=True)\n",
    "\n",
    "merged_df = merged_df.loc[merged_df[\"proteinid\"].isin(dfprotein[\"uniprot\"])]\n",
    "merged_df = merged_df.loc[merged_df[\"otherid\"].isin(dfprotein[\"uniprot\"])]\n",
    "\n",
    "merged_df.rename(columns = {\"proteinid\":\"uniprot\"},inplace=True)\n",
    "merged_df = pd.merge(merged_df, dfprotein[['id', 'uniprot']], how='left', on = \"uniprot\")\n",
    "merged_df.drop(columns = [\"uniprot\"],inplace=True)\n",
    "merged_df.rename(columns = {\"id\":\"protein_id\"},inplace=True)\n",
    "\n",
    "merged_df.rename(columns = {\"otherid\":\"uniprot\"},inplace=True)\n",
    "merged_df = pd.merge(merged_df, dfprotein[['id', 'uniprot']], how='left', on = \"uniprot\")\n",
    "merged_df.drop(columns = [\"uniprot\"],inplace=True)\n",
    "merged_df.rename(columns = {\"id\":\"other_id\"},inplace=True)\n",
    "\n",
    "dfppi = merged_df\n",
    "dfppi.rename(columns={'protein_id': 'protein_id1', 'other_id':'protein_id2'}, inplace=True)\n",
    "res = (dfppi[~dfppi.filter(like='protein_id').apply(frozenset, axis=1).duplicated()]\n",
    "       .reset_index(drop=True))\n",
    "res2 = res.pivot_table(\n",
    "    values='score', index='protein_id1', columns='protein_id2')\n",
    "res2.columns.name = None\n",
    "dfppi = res2.reset_index()\n",
    "dfppi = dfppi.add_prefix('PPI:')\n",
    "dfppi.rename(columns = {'PPI:protein_id1':'protein_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for GTEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine all the dfs \n",
    "dfprotein.rename(columns={'id': 'protein_id'}, inplace=True)\n",
    "\n",
    "df = dfhpa[dfhpa['tissue'].notna()]\n",
    "hpadf = pd.crosstab(df[\"protein_id\"], df[\"tissue\"]).reset_index().rename_axis(columns=None)\n",
    "\n",
    "df = dfgo[dfgo['go_id'].notna()]\n",
    "godf = pd.crosstab(df[\"protein_id\"], df[\"go_id\"]).reset_index().rename_axis(columns=None)\n",
    "\n",
    "df = dfpathway[dfpathway['id_in_source'].notna()]\n",
    "pathwaydf = pd.crosstab(df[\"protein_id\"], df[\"id_in_source\"]).reset_index().rename_axis(columns=None)\n",
    "\n",
    "df = dfppi\n",
    "ppidf = df \n",
    "\n",
    "df = dfgtex[dfgtex['tissue'].notna()]\n",
    "gtexdf = pd.crosstab(df[\"protein_id\"], df[\"tissue\"]).reset_index().rename_axis(columns=None)\n",
    "\n",
    "df1 = dfprotein.set_index('protein_id')\n",
    "df2 = godf.set_index('protein_id')\n",
    "df3 = pathwaydf.set_index('protein_id')\n",
    "df4 = hpadf.set_index('protein_id')\n",
    "df5 = ppidf.set_index('protein_id')\n",
    "\n",
    "df6 = gtexdf.set_index('protein_id')\n",
    "gtex = df6\n",
    "df = pd.concat([df1,df2,df3,df4, df5, df6],axis=1,sort=False).reset_index()\n",
    "df.rename(columns = {'index':'protein_id'})\n",
    "df.to_csv(\"v3data.csv\", index=False) \n",
    "df.to_feather('v3data.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for LINCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dflincs = pd.read_table('lincs.tsv') # lincs data from pharos at: https://drive.google.com/drive/folders/1P3-cBICdSzdXf7fiVS9qtKjdMZLANnwG?usp=sharing\n",
    "dflincs = dflincs.drop('Unnamed: 0', axis=1)\n",
    "dflincs = dflincs.add_prefix('LINCS:')\n",
    "dflincs.rename(columns = {'LINCS:protein_id':'protein_id'}, inplace=True)\n",
    "df = dflincs\n",
    "lincsdf = df\n",
    "\n",
    "df6 = lincsdf.set_index('protein_id')\n",
    "lincs = df6\n",
    "\n",
    "df = pd.concat([df1,df2,df3,df4, df5, df6],axis=1,sort=False).reset_index()\n",
    "df.rename(columns = {'index':'protein_id'})\n",
    "df.to_csv(\"v4data.csv\", index=False) \n",
    "df.to_feather('v4data.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for DISEASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = dfdis[dfdis['did'].notna()]\n",
    "disdf = pd.crosstab(df[\"protein_id\"], df[\"did\"]).reset_index().rename_axis(columns=None)\n",
    "\n",
    "df6 = disdf.set_index('protein_id')\n",
    "dis = df6\n",
    "\n",
    "df = pd.concat([df1,df2,df3,df4, df5, df6],axis=1,sort=False).reset_index()\n",
    "df.rename(columns = {'index':'protein_id'})\n",
    "df.to_csv(\"v5data.csv\", index=False) \n",
    "df.to_feather('v5data.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for CCLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfccle = pd.read_table('ccle.tsv') # ccle data from pharos at: https://drive.google.com/drive/folders/1P3-cBICdSzdXf7fiVS9qtKjdMZLANnwG?usp=sharing\n",
    "dfccle = dfccle.drop('Unnamed: 0', axis=1)\n",
    "dfccle.columns = dfccle.columns.str.split('(').str[-1]\n",
    "dfccle.columns = dfccle.columns.str.replace(')', '')\n",
    "\n",
    "df = dfccle\n",
    "ccledf = df\n",
    "\n",
    "df6 = ccledf.set_index('protein_id')\n",
    "ccle = df6\n",
    "\n",
    "df = pd.concat([df1,df2,df3,df4, df5, df6],axis=1,sort=False).reset_index()\n",
    "df.rename(columns = {'index':'protein_id'})\n",
    "df.to_csv(\"v6data.csv\", index=False) \n",
    "df.to_feather('v6data.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for _ALL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2,df3,df4, df5, gtex, lincs, dis, ccle],axis=1,sort=False).reset_index()\n",
    "df.rename(columns = {'index':'protein_id'})\n",
    "df.dropna(subset=['uniprot'], inplace=True)\n",
    "df.to_feather('v13data.feather') # data for _ALL models"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPvCDhdwnMye3251VfBoMQ3",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-jhub_2]",
   "language": "python",
   "name": "conda-env-.conda-jhub_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
